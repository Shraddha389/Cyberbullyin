{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2db77398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf4a9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28614, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hate ppl high school used bully hot omg love m...</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kat andre asshole omg mkr</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new access trading cause need high level opini...</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fuck david duke racist think america belong du...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>may say lot hate apologetic army hope choke ev...</td>\n",
       "      <td>other_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>breanichole rapeisntokay made gay joke rape jo...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hindustan time report gay rape joke taken obje...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>willy real man know able cook one attractive q...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>notallmen evolving notallmen evolved blameonen...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anirban stupid mamata regime hundred bjp worke...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_tweet   cyberbullying_type\n",
       "0  hate ppl high school used bully hot omg love m...                  age\n",
       "1                          kat andre asshole omg mkr    not_cyberbullying\n",
       "2  new access trading cause need high level opini...                  age\n",
       "3  fuck david duke racist think america belong du...            ethnicity\n",
       "4  may say lot hate apologetic army hope choke ev...  other_cyberbullying\n",
       "5  breanichole rapeisntokay made gay joke rape jo...               gender\n",
       "6  hindustan time report gay rape joke taken obje...               gender\n",
       "7  willy real man know able cook one attractive q...               gender\n",
       "8  notallmen evolving notallmen evolved blameonen...               gender\n",
       "9  anirban stupid mamata regime hundred bjp worke...             religion"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the dataset into a dataframe\n",
    "df = pd.read_csv('../../data/train_data.csv')\n",
    "\n",
    "display(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5367824a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check if null value exist\n",
    "display(df.clean_tweet.isna().sum())\n",
    "\n",
    "# replace null values with empty string\n",
    "df.clean_tweet = df.clean_tweet.fillna('')\n",
    "\n",
    "# verify null count\n",
    "display(df.clean_tweet.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ea469c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [hate, ppl, high, school, used, bully, hot, om...\n",
       "1                      [kat, andre, asshole, omg, mkr]\n",
       "2    [new, access, trading, cause, need, high, leve...\n",
       "3    [fuck, david, duke, racist, think, america, be...\n",
       "4    [may, say, lot, hate, apologetic, army, hope, ...\n",
       "Name: clean_tweet, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# required tokenization for word2vec\n",
    "tweets = df.clean_tweet.apply(simple_preprocess)\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cf15bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNot training a new word2vec model.\\nA model has already been trained and is loaded for further usage.\\nUncomment the code block to train and save a new model.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Not training a new word2vec model.\n",
    "A model has already been trained and is loaded for further usage.\n",
    "Uncomment the code block to train and save a new model.\n",
    "\"\"\"\n",
    "# spawn a Word2Vec model\n",
    "# model = Word2Vec(window=5, min_count=2)\n",
    "\n",
    "# build vocabulary from entire corpus\n",
    "# model.build_vocab(tweets, progress_per=1000)\n",
    "\n",
    "# train the word2vec\n",
    "# model.train(tweets, total_examples=model.corpus_count, epochs=5)\n",
    "\n",
    "# save the model\n",
    "# commented to avoid overwriting the trained model\n",
    "# model.save(\"../../models/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c7f1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a trained model\n",
    "model = Word2Vec.load('../../models/word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c309226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('middle', 0.965322732925415),\n",
       " ('elementary', 0.9573146104812622),\n",
       " ('high', 0.9516770839691162),\n",
       " ('graduation', 0.9479526877403259),\n",
       " ('relentlessly', 0.9460520148277283),\n",
       " ('confrontation', 0.9452431201934814),\n",
       " ('grade', 0.9413620829582214),\n",
       " ('teased', 0.9374991059303284),\n",
       " ('teacher', 0.9353218674659729),\n",
       " ('tormentor', 0.9342045187950134)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('trayvon', 0.9649240970611572),\n",
       " ('shut', 0.9571725130081177),\n",
       " ('goshawty', 0.9547345042228699),\n",
       " ('sayin', 0.9497713446617126),\n",
       " ('ignorant', 0.9482175707817078),\n",
       " ('stupid', 0.9463467001914978),\n",
       " ('spic', 0.9458626508712769),\n",
       " ('beaner', 0.9441934823989868),\n",
       " ('nigga', 0.9439464807510376),\n",
       " ('subban', 0.9413833022117615)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# top 10 similar words\n",
    "# similar to bully\n",
    "display(model.wv.most_similar('bully'))\n",
    "\n",
    "# similar to dumb\n",
    "display(model.wv.most_similar('dumb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f5d01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93749917"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# word-word cosine similarity\n",
    "display(model.wv.similarity(w1='bully', w2='teased'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76cc96d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14964, 100)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>swim</th>\n",
       "      <td>-0.016192</td>\n",
       "      <td>0.050970</td>\n",
       "      <td>0.038516</td>\n",
       "      <td>0.031989</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>-0.164538</td>\n",
       "      <td>0.023973</td>\n",
       "      <td>0.169723</td>\n",
       "      <td>-0.050496</td>\n",
       "      <td>-0.062756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049447</td>\n",
       "      <td>0.039125</td>\n",
       "      <td>-0.003252</td>\n",
       "      <td>0.063031</td>\n",
       "      <td>0.125179</td>\n",
       "      <td>0.041714</td>\n",
       "      <td>0.014036</td>\n",
       "      <td>-0.067356</td>\n",
       "      <td>0.026716</td>\n",
       "      <td>-0.063782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cranboonitz</th>\n",
       "      <td>-0.010225</td>\n",
       "      <td>0.020895</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>0.011847</td>\n",
       "      <td>0.010744</td>\n",
       "      <td>-0.082252</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.082809</td>\n",
       "      <td>-0.036677</td>\n",
       "      <td>-0.028743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034996</td>\n",
       "      <td>0.030146</td>\n",
       "      <td>-0.004744</td>\n",
       "      <td>0.025941</td>\n",
       "      <td>0.064958</td>\n",
       "      <td>0.028077</td>\n",
       "      <td>-0.001096</td>\n",
       "      <td>-0.035168</td>\n",
       "      <td>0.036120</td>\n",
       "      <td>-0.042367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incoherent</th>\n",
       "      <td>-0.007473</td>\n",
       "      <td>0.008760</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.009725</td>\n",
       "      <td>-0.009150</td>\n",
       "      <td>-0.035808</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.032312</td>\n",
       "      <td>-0.014842</td>\n",
       "      <td>-0.013401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.013164</td>\n",
       "      <td>-0.012924</td>\n",
       "      <td>0.014233</td>\n",
       "      <td>0.011315</td>\n",
       "      <td>0.005745</td>\n",
       "      <td>-0.007297</td>\n",
       "      <td>-0.012274</td>\n",
       "      <td>0.012156</td>\n",
       "      <td>-0.031773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>succeeding</th>\n",
       "      <td>-0.009584</td>\n",
       "      <td>0.019142</td>\n",
       "      <td>0.012872</td>\n",
       "      <td>0.018994</td>\n",
       "      <td>-0.001779</td>\n",
       "      <td>-0.085978</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.083965</td>\n",
       "      <td>-0.021903</td>\n",
       "      <td>-0.017847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023065</td>\n",
       "      <td>0.011557</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.049353</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>-0.036715</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>-0.036695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalisation</th>\n",
       "      <td>-0.017711</td>\n",
       "      <td>0.016516</td>\n",
       "      <td>-0.012281</td>\n",
       "      <td>-0.013805</td>\n",
       "      <td>-0.009014</td>\n",
       "      <td>-0.038469</td>\n",
       "      <td>-0.011118</td>\n",
       "      <td>0.037006</td>\n",
       "      <td>-0.001551</td>\n",
       "      <td>-0.005401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>0.017186</td>\n",
       "      <td>-0.005662</td>\n",
       "      <td>-0.004786</td>\n",
       "      <td>0.017323</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.010320</td>\n",
       "      <td>-0.031333</td>\n",
       "      <td>0.013886</td>\n",
       "      <td>-0.007870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kent</th>\n",
       "      <td>-0.017487</td>\n",
       "      <td>0.019351</td>\n",
       "      <td>0.021287</td>\n",
       "      <td>0.017192</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.068852</td>\n",
       "      <td>0.018296</td>\n",
       "      <td>0.073776</td>\n",
       "      <td>-0.015681</td>\n",
       "      <td>-0.033791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029810</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>-0.004460</td>\n",
       "      <td>0.030831</td>\n",
       "      <td>0.055547</td>\n",
       "      <td>0.022893</td>\n",
       "      <td>-0.003331</td>\n",
       "      <td>-0.043318</td>\n",
       "      <td>0.017207</td>\n",
       "      <td>-0.016921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recover</th>\n",
       "      <td>-0.023670</td>\n",
       "      <td>0.038805</td>\n",
       "      <td>0.020255</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>-0.004227</td>\n",
       "      <td>-0.100927</td>\n",
       "      <td>0.012175</td>\n",
       "      <td>0.113186</td>\n",
       "      <td>-0.025910</td>\n",
       "      <td>-0.040676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044634</td>\n",
       "      <td>0.039185</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>0.021925</td>\n",
       "      <td>0.062281</td>\n",
       "      <td>0.029010</td>\n",
       "      <td>0.004452</td>\n",
       "      <td>-0.048802</td>\n",
       "      <td>0.015675</td>\n",
       "      <td>-0.026631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crazed</th>\n",
       "      <td>-0.005717</td>\n",
       "      <td>0.011034</td>\n",
       "      <td>0.009325</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>-0.064414</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>0.056345</td>\n",
       "      <td>-0.013250</td>\n",
       "      <td>-0.023054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019664</td>\n",
       "      <td>0.014016</td>\n",
       "      <td>-0.010190</td>\n",
       "      <td>0.018581</td>\n",
       "      <td>0.030296</td>\n",
       "      <td>0.013156</td>\n",
       "      <td>0.014322</td>\n",
       "      <td>-0.037855</td>\n",
       "      <td>0.006867</td>\n",
       "      <td>-0.011776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coexistence</th>\n",
       "      <td>-0.013657</td>\n",
       "      <td>0.020463</td>\n",
       "      <td>0.007536</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.010045</td>\n",
       "      <td>-0.088340</td>\n",
       "      <td>-0.003483</td>\n",
       "      <td>0.094027</td>\n",
       "      <td>-0.013458</td>\n",
       "      <td>-0.022870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023668</td>\n",
       "      <td>0.033182</td>\n",
       "      <td>-0.009076</td>\n",
       "      <td>0.023085</td>\n",
       "      <td>0.059465</td>\n",
       "      <td>0.028899</td>\n",
       "      <td>-0.005369</td>\n",
       "      <td>-0.038665</td>\n",
       "      <td>0.030819</td>\n",
       "      <td>-0.032433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>secondlady</th>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-0.003906</td>\n",
       "      <td>-0.000442</td>\n",
       "      <td>0.009225</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>-0.033619</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.038287</td>\n",
       "      <td>-0.012577</td>\n",
       "      <td>-0.006833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033234</td>\n",
       "      <td>0.012307</td>\n",
       "      <td>-0.016917</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.021932</td>\n",
       "      <td>-0.021543</td>\n",
       "      <td>-0.022388</td>\n",
       "      <td>0.014168</td>\n",
       "      <td>-0.016251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0         1         2         3         4         5   \\\n",
       "swim           -0.016192  0.050970  0.038516  0.031989  0.006755 -0.164538   \n",
       "cranboonitz    -0.010225  0.020895  0.006692  0.011847  0.010744 -0.082252   \n",
       "incoherent     -0.007473  0.008760  0.002317  0.009725 -0.009150 -0.035808   \n",
       "succeeding     -0.009584  0.019142  0.012872  0.018994 -0.001779 -0.085978   \n",
       "generalisation -0.017711  0.016516 -0.012281 -0.013805 -0.009014 -0.038469   \n",
       "kent           -0.017487  0.019351  0.021287  0.017192  0.002861 -0.068852   \n",
       "recover        -0.023670  0.038805  0.020255  0.024430 -0.004227 -0.100927   \n",
       "crazed         -0.005717  0.011034  0.009325  0.001767  0.005527 -0.064414   \n",
       "coexistence    -0.013657  0.020463  0.007536 -0.000164 -0.010045 -0.088340   \n",
       "secondlady     -0.000058 -0.003906 -0.000442  0.009225  0.000936 -0.033619   \n",
       "\n",
       "                      6         7         8         9   ...        90  \\\n",
       "swim            0.023973  0.169723 -0.050496 -0.062756  ...  0.049447   \n",
       "cranboonitz     0.005391  0.082809 -0.036677 -0.028743  ...  0.034996   \n",
       "incoherent      0.003866  0.032312 -0.014842 -0.013401  ...  0.006639   \n",
       "succeeding      0.003166  0.083965 -0.021903 -0.017847  ...  0.023065   \n",
       "generalisation -0.011118  0.037006 -0.001551 -0.005401  ...  0.019917   \n",
       "kent            0.018296  0.073776 -0.015681 -0.033791  ...  0.029810   \n",
       "recover         0.012175  0.113186 -0.025910 -0.040676  ...  0.044634   \n",
       "crazed          0.008706  0.056345 -0.013250 -0.023054  ...  0.019664   \n",
       "coexistence    -0.003483  0.094027 -0.013458 -0.022870  ...  0.023668   \n",
       "secondlady      0.005092  0.038287 -0.012577 -0.006833  ...  0.033234   \n",
       "\n",
       "                      91        92        93        94        95        96  \\\n",
       "swim            0.039125 -0.003252  0.063031  0.125179  0.041714  0.014036   \n",
       "cranboonitz     0.030146 -0.004744  0.025941  0.064958  0.028077 -0.001096   \n",
       "incoherent      0.013164 -0.012924  0.014233  0.011315  0.005745 -0.007297   \n",
       "succeeding      0.011557  0.002887  0.026443  0.049353  0.012399  0.004975   \n",
       "generalisation  0.017186 -0.005662 -0.004786  0.017323  0.009752  0.010320   \n",
       "kent            0.017921 -0.004460  0.030831  0.055547  0.022893 -0.003331   \n",
       "recover         0.039185 -0.001975  0.021925  0.062281  0.029010  0.004452   \n",
       "crazed          0.014016 -0.010190  0.018581  0.030296  0.013156  0.014322   \n",
       "coexistence     0.033182 -0.009076  0.023085  0.059465  0.028899 -0.005369   \n",
       "secondlady      0.012307 -0.016917  0.002611  0.004178  0.021932 -0.021543   \n",
       "\n",
       "                      97        98        99  \n",
       "swim           -0.067356  0.026716 -0.063782  \n",
       "cranboonitz    -0.035168  0.036120 -0.042367  \n",
       "incoherent     -0.012274  0.012156 -0.031773  \n",
       "succeeding     -0.036715  0.016611 -0.036695  \n",
       "generalisation -0.031333  0.013886 -0.007870  \n",
       "kent           -0.043318  0.017207 -0.016921  \n",
       "recover        -0.048802  0.015675 -0.026631  \n",
       "crazed         -0.037855  0.006867 -0.011776  \n",
       "coexistence    -0.038665  0.030819 -0.032433  \n",
       "secondlady     -0.022388  0.014168 -0.016251  \n",
       "\n",
       "[10 rows x 100 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract word vectors as dataframe from the model\n",
    "word_vectors = pd.DataFrame([model.wv.get_vector(str(word)) for word in model.wv.key_to_index], index = model.wv.key_to_index)\n",
    "\n",
    "display(word_vectors.shape)\n",
    "word_vectors.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58f3259e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28614, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate document matrix from word vectors\n",
    "document_matrix = []\n",
    "words = set(model.wv.index_to_key)\n",
    "\n",
    "for tweet in tweets:\n",
    "    tweet_vector = np.zeros(100)\n",
    "    for word in tweet:\n",
    "        if word in model.wv.index_to_key:\n",
    "            tweet_vector += model.wv[word]\n",
    "    tweet_vector = tweet_vector if len(tweet)==0 else (tweet_vector/len(tweet))\n",
    "    document_matrix.append(tweet_vector)\n",
    "    \n",
    "len(document_matrix), len(document_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96177d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28614, 101)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.237988</td>\n",
       "      <td>0.411318</td>\n",
       "      <td>0.153711</td>\n",
       "      <td>0.382920</td>\n",
       "      <td>0.262672</td>\n",
       "      <td>-1.023562</td>\n",
       "      <td>0.585043</td>\n",
       "      <td>1.101426</td>\n",
       "      <td>-0.876988</td>\n",
       "      <td>-0.330105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294901</td>\n",
       "      <td>0.098529</td>\n",
       "      <td>0.473230</td>\n",
       "      <td>1.009498</td>\n",
       "      <td>0.419733</td>\n",
       "      <td>-0.015129</td>\n",
       "      <td>-0.419448</td>\n",
       "      <td>0.251839</td>\n",
       "      <td>-0.210250</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.144806</td>\n",
       "      <td>0.617245</td>\n",
       "      <td>0.748015</td>\n",
       "      <td>0.834076</td>\n",
       "      <td>0.283397</td>\n",
       "      <td>-1.274383</td>\n",
       "      <td>0.156880</td>\n",
       "      <td>1.549933</td>\n",
       "      <td>-0.290592</td>\n",
       "      <td>-0.279230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316109</td>\n",
       "      <td>0.147053</td>\n",
       "      <td>0.433169</td>\n",
       "      <td>0.932522</td>\n",
       "      <td>-0.024955</td>\n",
       "      <td>0.404652</td>\n",
       "      <td>-0.522447</td>\n",
       "      <td>-0.422570</td>\n",
       "      <td>-0.535668</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.146266</td>\n",
       "      <td>0.386033</td>\n",
       "      <td>0.010834</td>\n",
       "      <td>0.229401</td>\n",
       "      <td>0.296175</td>\n",
       "      <td>-0.986068</td>\n",
       "      <td>0.512315</td>\n",
       "      <td>1.086754</td>\n",
       "      <td>-0.742112</td>\n",
       "      <td>-0.268087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360697</td>\n",
       "      <td>0.038448</td>\n",
       "      <td>0.503674</td>\n",
       "      <td>0.955136</td>\n",
       "      <td>0.387838</td>\n",
       "      <td>-0.007955</td>\n",
       "      <td>-0.412584</td>\n",
       "      <td>0.386322</td>\n",
       "      <td>-0.276698</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.010017</td>\n",
       "      <td>0.101545</td>\n",
       "      <td>0.185687</td>\n",
       "      <td>-0.089176</td>\n",
       "      <td>-0.120168</td>\n",
       "      <td>-1.224311</td>\n",
       "      <td>0.320136</td>\n",
       "      <td>1.062363</td>\n",
       "      <td>-0.440994</td>\n",
       "      <td>-0.509981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199142</td>\n",
       "      <td>0.278352</td>\n",
       "      <td>0.094113</td>\n",
       "      <td>0.765693</td>\n",
       "      <td>0.206304</td>\n",
       "      <td>0.292828</td>\n",
       "      <td>-0.481870</td>\n",
       "      <td>-0.140193</td>\n",
       "      <td>-0.005416</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.050589</td>\n",
       "      <td>0.187251</td>\n",
       "      <td>0.080036</td>\n",
       "      <td>0.021537</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>-0.789317</td>\n",
       "      <td>0.276012</td>\n",
       "      <td>0.801677</td>\n",
       "      <td>-0.326183</td>\n",
       "      <td>-0.302832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250055</td>\n",
       "      <td>0.083603</td>\n",
       "      <td>0.199339</td>\n",
       "      <td>0.573685</td>\n",
       "      <td>0.278995</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>-0.340371</td>\n",
       "      <td>0.115137</td>\n",
       "      <td>-0.216936</td>\n",
       "      <td>other_cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.237988  0.411318  0.153711  0.382920  0.262672 -1.023562  0.585043   \n",
       "1 -0.144806  0.617245  0.748015  0.834076  0.283397 -1.274383  0.156880   \n",
       "2 -0.146266  0.386033  0.010834  0.229401  0.296175 -0.986068  0.512315   \n",
       "3 -0.010017  0.101545  0.185687 -0.089176 -0.120168 -1.224311  0.320136   \n",
       "4 -0.050589  0.187251  0.080036  0.021537  0.001453 -0.789317  0.276012   \n",
       "\n",
       "          7         8         9  ...        91        92        93        94  \\\n",
       "0  1.101426 -0.876988 -0.330105  ...  0.294901  0.098529  0.473230  1.009498   \n",
       "1  1.549933 -0.290592 -0.279230  ... -0.316109  0.147053  0.433169  0.932522   \n",
       "2  1.086754 -0.742112 -0.268087  ...  0.360697  0.038448  0.503674  0.955136   \n",
       "3  1.062363 -0.440994 -0.509981  ...  0.199142  0.278352  0.094113  0.765693   \n",
       "4  0.801677 -0.326183 -0.302832  ...  0.250055  0.083603  0.199339  0.573685   \n",
       "\n",
       "         95        96        97        98        99   cyberbullying_type  \n",
       "0  0.419733 -0.015129 -0.419448  0.251839 -0.210250                  age  \n",
       "1 -0.024955  0.404652 -0.522447 -0.422570 -0.535668    not_cyberbullying  \n",
       "2  0.387838 -0.007955 -0.412584  0.386322 -0.276698                  age  \n",
       "3  0.206304  0.292828 -0.481870 -0.140193 -0.005416            ethnicity  \n",
       "4  0.278995  0.017548 -0.340371  0.115137 -0.216936  other_cyberbullying  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert document matrix to dataframe\n",
    "df_w2v = pd.DataFrame(document_matrix)\n",
    "\n",
    "# include the class labels\n",
    "df_w2v['cyberbullying_type'] = df['cyberbullying_type']\n",
    "\n",
    "display(df_w2v.shape)\n",
    "df_w2v.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
