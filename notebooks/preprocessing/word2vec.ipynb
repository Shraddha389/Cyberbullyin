{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2db77398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf4a9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28614, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hate ppl high school used bully hot omg love m...</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kat andre asshole omg mkr</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new access trading cause need high level opini...</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fuck david duke racist think america belong du...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>may say lot hate apologetic army hope choke ev...</td>\n",
       "      <td>other_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>breanichole rapeisntokay made gay joke rape jo...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hindustan time report gay rape joke taken obje...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>willy real man know able cook one attractive q...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>notallmen evolving notallmen evolved blameonen...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anirban stupid mamata regime hundred bjp worke...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_tweet   cyberbullying_type\n",
       "0  hate ppl high school used bully hot omg love m...                  age\n",
       "1                          kat andre asshole omg mkr    not_cyberbullying\n",
       "2  new access trading cause need high level opini...                  age\n",
       "3  fuck david duke racist think america belong du...            ethnicity\n",
       "4  may say lot hate apologetic army hope choke ev...  other_cyberbullying\n",
       "5  breanichole rapeisntokay made gay joke rape jo...               gender\n",
       "6  hindustan time report gay rape joke taken obje...               gender\n",
       "7  willy real man know able cook one attractive q...               gender\n",
       "8  notallmen evolving notallmen evolved blameonen...               gender\n",
       "9  anirban stupid mamata regime hundred bjp worke...             religion"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the dataset into a dataframe\n",
    "df = pd.read_csv('../../data/train_data.csv')\n",
    "\n",
    "display(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5367824a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check if null value exist\n",
    "display(df.clean_tweet.isna().sum())\n",
    "\n",
    "# replace null values with empty string\n",
    "df.clean_tweet = df.clean_tweet.fillna('')\n",
    "\n",
    "# verify null count\n",
    "display(df.clean_tweet.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ea469c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [hate, ppl, high, school, used, bully, hot, om...\n",
       "1                      [kat, andre, asshole, omg, mkr]\n",
       "2    [new, access, trading, cause, need, high, leve...\n",
       "3    [fuck, david, duke, racist, think, america, be...\n",
       "4    [may, say, lot, hate, apologetic, army, hope, ...\n",
       "Name: clean_tweet, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# required tokenization for word2vec\n",
    "tweets = df.clean_tweet.apply(simple_preprocess)\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cf15bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNot training a new word2vec model.\\nA model has already been trained and is loaded for further usage.\\nUncomment the code block to train and save a new model.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Not training a new word2vec model.\n",
    "A model has already been trained and is loaded for further usage.\n",
    "Uncomment the code block to train and save a new model.\n",
    "\"\"\"\n",
    "# spawn a Word2Vec model\n",
    "# model = Word2Vec(window=5, min_count=2)\n",
    "\n",
    "# build vocabulary from entire corpus\n",
    "# model.build_vocab(tweets, progress_per=1000)\n",
    "\n",
    "# train the word2vec\n",
    "# model.train(tweets, total_examples=model.corpus_count, epochs=5)\n",
    "\n",
    "# save the model\n",
    "# commented to avoid overwriting the trained model\n",
    "# model.save(\"../../models/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c7f1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a trained model\n",
    "model = Word2Vec.load('../../models/word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c309226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('middle', 0.965322732925415),\n",
       " ('elementary', 0.9573146104812622),\n",
       " ('high', 0.9516770839691162),\n",
       " ('graduation', 0.9479526877403259),\n",
       " ('relentlessly', 0.9460520148277283),\n",
       " ('confrontation', 0.9452431201934814),\n",
       " ('grade', 0.9413620829582214),\n",
       " ('teased', 0.9374991059303284),\n",
       " ('teacher', 0.9353218674659729),\n",
       " ('tormentor', 0.9342045187950134)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('trayvon', 0.9649240970611572),\n",
       " ('shut', 0.9571725130081177),\n",
       " ('goshawty', 0.9547345042228699),\n",
       " ('sayin', 0.9497713446617126),\n",
       " ('ignorant', 0.9482175707817078),\n",
       " ('stupid', 0.9463467001914978),\n",
       " ('spic', 0.9458626508712769),\n",
       " ('beaner', 0.9441934823989868),\n",
       " ('nigga', 0.9439464807510376),\n",
       " ('subban', 0.9413833022117615)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# top 10 similar words\n",
    "# similar to bully\n",
    "display(model.wv.most_similar('bully'))\n",
    "\n",
    "# similar to dumb\n",
    "display(model.wv.most_similar('dumb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f5d01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93749917"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# word-word cosine similarity\n",
    "display(model.wv.similarity(w1='bully', w2='teased'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76cc96d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14964, 100)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fiving</th>\n",
       "      <td>-0.004180</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.008864</td>\n",
       "      <td>0.030317</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>-0.040311</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>0.032164</td>\n",
       "      <td>-0.017889</td>\n",
       "      <td>-0.017366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.011613</td>\n",
       "      <td>0.010849</td>\n",
       "      <td>0.023160</td>\n",
       "      <td>0.032840</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>-0.000905</td>\n",
       "      <td>-0.024694</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>-0.018908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inclusive</th>\n",
       "      <td>-0.008973</td>\n",
       "      <td>0.017072</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>-0.135618</td>\n",
       "      <td>0.014574</td>\n",
       "      <td>0.132379</td>\n",
       "      <td>-0.040094</td>\n",
       "      <td>-0.039930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066306</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>-0.002961</td>\n",
       "      <td>0.029912</td>\n",
       "      <td>0.095546</td>\n",
       "      <td>0.033747</td>\n",
       "      <td>0.013989</td>\n",
       "      <td>-0.073101</td>\n",
       "      <td>0.017821</td>\n",
       "      <td>-0.043935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thegeek</th>\n",
       "      <td>-0.024262</td>\n",
       "      <td>0.030241</td>\n",
       "      <td>0.031196</td>\n",
       "      <td>0.020661</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>-0.075843</td>\n",
       "      <td>0.014947</td>\n",
       "      <td>0.095824</td>\n",
       "      <td>-0.015683</td>\n",
       "      <td>-0.029006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023302</td>\n",
       "      <td>0.008798</td>\n",
       "      <td>0.012101</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.049220</td>\n",
       "      <td>0.018428</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>-0.037559</td>\n",
       "      <td>0.016661</td>\n",
       "      <td>-0.014965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruction</th>\n",
       "      <td>-0.018524</td>\n",
       "      <td>0.026947</td>\n",
       "      <td>0.024693</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>-0.005835</td>\n",
       "      <td>-0.064576</td>\n",
       "      <td>0.019627</td>\n",
       "      <td>0.075655</td>\n",
       "      <td>-0.018632</td>\n",
       "      <td>-0.026387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024665</td>\n",
       "      <td>0.017041</td>\n",
       "      <td>-0.003775</td>\n",
       "      <td>0.018352</td>\n",
       "      <td>0.050005</td>\n",
       "      <td>0.015278</td>\n",
       "      <td>-0.009907</td>\n",
       "      <td>-0.025241</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>-0.019569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colin</th>\n",
       "      <td>-0.099874</td>\n",
       "      <td>0.301789</td>\n",
       "      <td>0.227966</td>\n",
       "      <td>0.232600</td>\n",
       "      <td>0.103665</td>\n",
       "      <td>-0.711918</td>\n",
       "      <td>0.092800</td>\n",
       "      <td>0.856416</td>\n",
       "      <td>-0.213289</td>\n",
       "      <td>-0.163051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217306</td>\n",
       "      <td>0.063866</td>\n",
       "      <td>0.019978</td>\n",
       "      <td>0.255847</td>\n",
       "      <td>0.524943</td>\n",
       "      <td>0.084402</td>\n",
       "      <td>0.113449</td>\n",
       "      <td>-0.325788</td>\n",
       "      <td>0.028994</td>\n",
       "      <td>-0.272696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalked</th>\n",
       "      <td>-0.017090</td>\n",
       "      <td>0.024763</td>\n",
       "      <td>0.011745</td>\n",
       "      <td>0.007520</td>\n",
       "      <td>0.005819</td>\n",
       "      <td>-0.078474</td>\n",
       "      <td>0.008721</td>\n",
       "      <td>0.076405</td>\n",
       "      <td>-0.028536</td>\n",
       "      <td>-0.033842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036380</td>\n",
       "      <td>0.018124</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>0.022091</td>\n",
       "      <td>0.059580</td>\n",
       "      <td>0.029134</td>\n",
       "      <td>0.011851</td>\n",
       "      <td>-0.030349</td>\n",
       "      <td>0.020929</td>\n",
       "      <td>-0.027264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mena</th>\n",
       "      <td>0.004329</td>\n",
       "      <td>-0.002214</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>-0.000954</td>\n",
       "      <td>-0.000661</td>\n",
       "      <td>-0.013937</td>\n",
       "      <td>-0.010625</td>\n",
       "      <td>0.007285</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>-0.002357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.009965</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.001533</td>\n",
       "      <td>-0.007548</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>-0.010528</td>\n",
       "      <td>-0.000418</td>\n",
       "      <td>0.015278</td>\n",
       "      <td>-0.009482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbo</th>\n",
       "      <td>-0.022434</td>\n",
       "      <td>0.026545</td>\n",
       "      <td>0.020067</td>\n",
       "      <td>0.023420</td>\n",
       "      <td>-0.003905</td>\n",
       "      <td>-0.082668</td>\n",
       "      <td>0.007425</td>\n",
       "      <td>0.091665</td>\n",
       "      <td>-0.032794</td>\n",
       "      <td>-0.037276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039163</td>\n",
       "      <td>0.012248</td>\n",
       "      <td>0.010094</td>\n",
       "      <td>0.016206</td>\n",
       "      <td>0.068377</td>\n",
       "      <td>0.026077</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>-0.047634</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>-0.033175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brittney</th>\n",
       "      <td>-0.001988</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.018347</td>\n",
       "      <td>0.014833</td>\n",
       "      <td>-0.013084</td>\n",
       "      <td>-0.029538</td>\n",
       "      <td>0.015529</td>\n",
       "      <td>0.025772</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>-0.017013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.013767</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>0.016327</td>\n",
       "      <td>0.014118</td>\n",
       "      <td>0.005040</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>-0.011509</td>\n",
       "      <td>-0.001157</td>\n",
       "      <td>-0.014647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diy</th>\n",
       "      <td>-0.012129</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>-0.005549</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>-0.029901</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>0.022592</td>\n",
       "      <td>-0.003955</td>\n",
       "      <td>-0.004976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011821</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>-0.002880</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.022141</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>-0.010040</td>\n",
       "      <td>-0.012927</td>\n",
       "      <td>0.009266</td>\n",
       "      <td>0.002957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4         5   \\\n",
       "fiving      -0.004180  0.011004  0.008864  0.030317  0.010306 -0.040311   \n",
       "inclusive   -0.008973  0.017072  0.026882  0.002646  0.002169 -0.135618   \n",
       "thegeek     -0.024262  0.030241  0.031196  0.020661  0.001705 -0.075843   \n",
       "instruction -0.018524  0.026947  0.024693  0.018911 -0.005835 -0.064576   \n",
       "colin       -0.099874  0.301789  0.227966  0.232600  0.103665 -0.711918   \n",
       "stalked     -0.017090  0.024763  0.011745  0.007520  0.005819 -0.078474   \n",
       "mena         0.004329 -0.002214  0.008523 -0.000954 -0.000661 -0.013937   \n",
       "symbo       -0.022434  0.026545  0.020067  0.023420 -0.003905 -0.082668   \n",
       "brittney    -0.001988  0.003320  0.018347  0.014833 -0.013084 -0.029538   \n",
       "diy         -0.012129  0.009449  0.004589 -0.005549  0.002820 -0.029901   \n",
       "\n",
       "                   6         7         8         9   ...        90        91  \\\n",
       "fiving       0.005436  0.032164 -0.017889 -0.017366  ...  0.014288  0.011613   \n",
       "inclusive    0.014574  0.132379 -0.040094 -0.039930  ...  0.066306  0.047500   \n",
       "thegeek      0.014947  0.095824 -0.015683 -0.029006  ...  0.023302  0.008798   \n",
       "instruction  0.019627  0.075655 -0.018632 -0.026387  ...  0.024665  0.017041   \n",
       "colin        0.092800  0.856416 -0.213289 -0.163051  ...  0.217306  0.063866   \n",
       "stalked      0.008721  0.076405 -0.028536 -0.033842  ...  0.036380  0.018124   \n",
       "mena        -0.010625  0.007285  0.007508 -0.002357  ...  0.002920  0.009965   \n",
       "symbo        0.007425  0.091665 -0.032794 -0.037276  ...  0.039163  0.012248   \n",
       "brittney     0.015529  0.025772  0.005558 -0.017013  ...  0.003783  0.013767   \n",
       "diy          0.004236  0.022592 -0.003955 -0.004976  ...  0.011821  0.004138   \n",
       "\n",
       "                   92        93        94        95        96        97  \\\n",
       "fiving       0.010849  0.023160  0.032840  0.003168 -0.000905 -0.024694   \n",
       "inclusive   -0.002961  0.029912  0.095546  0.033747  0.013989 -0.073101   \n",
       "thegeek      0.012101  0.011750  0.049220  0.018428  0.006829 -0.037559   \n",
       "instruction -0.003775  0.018352  0.050005  0.015278 -0.009907 -0.025241   \n",
       "colin        0.019978  0.255847  0.524943  0.084402  0.113449 -0.325788   \n",
       "stalked      0.004675  0.022091  0.059580  0.029134  0.011851 -0.030349   \n",
       "mena        -0.000119 -0.001533 -0.007548  0.009852 -0.010528 -0.000418   \n",
       "symbo        0.010094  0.016206  0.068377  0.026077  0.000694 -0.047634   \n",
       "brittney     0.004899  0.016327  0.014118  0.005040  0.005804 -0.011509   \n",
       "diy         -0.002880  0.001116  0.022141  0.002177 -0.010040 -0.012927   \n",
       "\n",
       "                   98        99  \n",
       "fiving       0.012800 -0.018908  \n",
       "inclusive    0.017821 -0.043935  \n",
       "thegeek      0.016661 -0.014965  \n",
       "instruction  0.022540 -0.019569  \n",
       "colin        0.028994 -0.272696  \n",
       "stalked      0.020929 -0.027264  \n",
       "mena         0.015278 -0.009482  \n",
       "symbo        0.002508 -0.033175  \n",
       "brittney    -0.001157 -0.014647  \n",
       "diy          0.009266  0.002957  \n",
       "\n",
       "[10 rows x 100 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract word vectors as dataframe from the model\n",
    "word_vectors = pd.DataFrame([model.wv.get_vector(str(word)) for word in model.wv.key_to_index], index = model.wv.key_to_index)\n",
    "\n",
    "display(word_vectors.shape)\n",
    "word_vectors.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58f3259e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28614, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate document vectors from word vectors\n",
    "document_vectors = []\n",
    "words = set(model.wv.index_to_key)\n",
    "\n",
    "for tweet in tweets:\n",
    "    tweet_vector = np.zeros(100)\n",
    "    for word in tweet:\n",
    "        if word in model.wv.index_to_key:\n",
    "            tweet_vector += model.wv[word]\n",
    "    tweet_vector = tweet_vector if len(tweet)==0 else (tweet_vector/len(tweet))\n",
    "    document_vectors.append(tweet_vector)\n",
    "    \n",
    "len(document_vectors), len(document_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96177d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28614, 101)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.237988</td>\n",
       "      <td>0.411318</td>\n",
       "      <td>0.153711</td>\n",
       "      <td>0.382920</td>\n",
       "      <td>0.262672</td>\n",
       "      <td>-1.023562</td>\n",
       "      <td>0.585043</td>\n",
       "      <td>1.101426</td>\n",
       "      <td>-0.876988</td>\n",
       "      <td>-0.330105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294901</td>\n",
       "      <td>0.098529</td>\n",
       "      <td>0.473230</td>\n",
       "      <td>1.009498</td>\n",
       "      <td>0.419733</td>\n",
       "      <td>-0.015129</td>\n",
       "      <td>-0.419448</td>\n",
       "      <td>0.251839</td>\n",
       "      <td>-0.210250</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.144806</td>\n",
       "      <td>0.617245</td>\n",
       "      <td>0.748015</td>\n",
       "      <td>0.834076</td>\n",
       "      <td>0.283397</td>\n",
       "      <td>-1.274383</td>\n",
       "      <td>0.156880</td>\n",
       "      <td>1.549933</td>\n",
       "      <td>-0.290592</td>\n",
       "      <td>-0.279230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316109</td>\n",
       "      <td>0.147053</td>\n",
       "      <td>0.433169</td>\n",
       "      <td>0.932522</td>\n",
       "      <td>-0.024955</td>\n",
       "      <td>0.404652</td>\n",
       "      <td>-0.522447</td>\n",
       "      <td>-0.422570</td>\n",
       "      <td>-0.535668</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.146266</td>\n",
       "      <td>0.386033</td>\n",
       "      <td>0.010834</td>\n",
       "      <td>0.229401</td>\n",
       "      <td>0.296175</td>\n",
       "      <td>-0.986068</td>\n",
       "      <td>0.512315</td>\n",
       "      <td>1.086754</td>\n",
       "      <td>-0.742112</td>\n",
       "      <td>-0.268087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360697</td>\n",
       "      <td>0.038448</td>\n",
       "      <td>0.503674</td>\n",
       "      <td>0.955136</td>\n",
       "      <td>0.387838</td>\n",
       "      <td>-0.007955</td>\n",
       "      <td>-0.412584</td>\n",
       "      <td>0.386322</td>\n",
       "      <td>-0.276698</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.010017</td>\n",
       "      <td>0.101545</td>\n",
       "      <td>0.185687</td>\n",
       "      <td>-0.089176</td>\n",
       "      <td>-0.120168</td>\n",
       "      <td>-1.224311</td>\n",
       "      <td>0.320136</td>\n",
       "      <td>1.062363</td>\n",
       "      <td>-0.440994</td>\n",
       "      <td>-0.509981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199142</td>\n",
       "      <td>0.278352</td>\n",
       "      <td>0.094113</td>\n",
       "      <td>0.765693</td>\n",
       "      <td>0.206304</td>\n",
       "      <td>0.292828</td>\n",
       "      <td>-0.481870</td>\n",
       "      <td>-0.140193</td>\n",
       "      <td>-0.005416</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.050589</td>\n",
       "      <td>0.187251</td>\n",
       "      <td>0.080036</td>\n",
       "      <td>0.021537</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>-0.789317</td>\n",
       "      <td>0.276012</td>\n",
       "      <td>0.801677</td>\n",
       "      <td>-0.326183</td>\n",
       "      <td>-0.302832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250055</td>\n",
       "      <td>0.083603</td>\n",
       "      <td>0.199339</td>\n",
       "      <td>0.573685</td>\n",
       "      <td>0.278995</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>-0.340371</td>\n",
       "      <td>0.115137</td>\n",
       "      <td>-0.216936</td>\n",
       "      <td>other_cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.237988  0.411318  0.153711  0.382920  0.262672 -1.023562  0.585043   \n",
       "1 -0.144806  0.617245  0.748015  0.834076  0.283397 -1.274383  0.156880   \n",
       "2 -0.146266  0.386033  0.010834  0.229401  0.296175 -0.986068  0.512315   \n",
       "3 -0.010017  0.101545  0.185687 -0.089176 -0.120168 -1.224311  0.320136   \n",
       "4 -0.050589  0.187251  0.080036  0.021537  0.001453 -0.789317  0.276012   \n",
       "\n",
       "          7         8         9  ...        91        92        93        94  \\\n",
       "0  1.101426 -0.876988 -0.330105  ...  0.294901  0.098529  0.473230  1.009498   \n",
       "1  1.549933 -0.290592 -0.279230  ... -0.316109  0.147053  0.433169  0.932522   \n",
       "2  1.086754 -0.742112 -0.268087  ...  0.360697  0.038448  0.503674  0.955136   \n",
       "3  1.062363 -0.440994 -0.509981  ...  0.199142  0.278352  0.094113  0.765693   \n",
       "4  0.801677 -0.326183 -0.302832  ...  0.250055  0.083603  0.199339  0.573685   \n",
       "\n",
       "         95        96        97        98        99   cyberbullying_type  \n",
       "0  0.419733 -0.015129 -0.419448  0.251839 -0.210250                  age  \n",
       "1 -0.024955  0.404652 -0.522447 -0.422570 -0.535668    not_cyberbullying  \n",
       "2  0.387838 -0.007955 -0.412584  0.386322 -0.276698                  age  \n",
       "3  0.206304  0.292828 -0.481870 -0.140193 -0.005416            ethnicity  \n",
       "4  0.278995  0.017548 -0.340371  0.115137 -0.216936  other_cyberbullying  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert document vectors to document matrix as dataframe\n",
    "document_matrix = pd.DataFrame(document_vectors)\n",
    "\n",
    "# include the class labels\n",
    "document_matrix['cyberbullying_type'] = df['cyberbullying_type']\n",
    "\n",
    "display(document_matrix.shape)\n",
    "document_matrix.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
